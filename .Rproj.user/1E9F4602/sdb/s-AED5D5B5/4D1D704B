{
    "contents" : "#R interface to the libstemmer librarry\nlibrary(\"SnowballC\")\n#twitter stream library\nlibrary(streamR)\n#string library that ensures all functions handle all errors,NAs,etc\nlibrary(stringr)\n#framework for text mining in R\nlibrary(tm)\n#provides an interface to MOA(Massive Online Analysis) functionality from R\nlibrary(RMOA)\n\nauth_file_path <-  paste0(getwd(), \"/../my_oauth.Rdata\")\nload(auth_file_path)\n\n#function to accept current model, new tweet and its correct classification and return the updated model\nget_updated_model <- function(mymodel, dtm_row, row_class, i) {\n  dtm_df <- as.data.frame(as.matrix(dtm_row))\n  dtm_df[i,\"label\"]= row_class\n  datastream <- datastream_dataframe(data=dtm_df)\n  mymodel <- trainMOA(model = mymodel, formula=label~., data = datastream, reset = FALSE, trace = FALSE)\n  return(mymodel)\n}\n\n#function to return the tweets required. Specify the timeout\nget_love_hate_tweets <- function(time){\n  tweet_file_path <-  paste0(getwd(), \"/../new_tweets.json\")\n  #Only get those tweets with love or hate in them\n  filterStream(tweet_file_path, track = c(\"love\", \"hate\"), timeout = time, oauth = my_oauth)\n  #data frame of tweets from the json file generated\n  tweets.df <- parseTweets(tweet_file_path, simplify = TRUE)\n  file.remove(tweet_file_path)\n  cat(\"love hate tweets recieved: \", nrow(tweets.df), \"\\n\")\n  return(tweets.df);\n}\n\n#remove excessive white spaces,symbols and return text\nget_tweet_text <- function(tweets.df){\n  return (data.frame(str_replace_all(tweets.df$text,\"[^[:graph:]]\", \" \")))\n}\n\n#Twitter AUthentication file that needs to be pregenerated. See file Generate_OAuth_Token.R\nload(auth_file_path)\n\n#data frame of tweets\ntrain_tweets.df=get_love_hate_tweets(3);\n\n#data frame with the text of the tweets\ntrain_tweets_new.df <- get_tweet_text(train_tweets.df);\n\n#function to return the tweet's classification\nget_sentiment <- function(x) {\n  love <- \"love\"\n  hate <- \"hate\"\n  \n  if(str_detect(x, \"love\")) {\n    love \n  }\n  else {\n    hate\n  }\n}\n\n#get the classification of each tweet\ntrain_org_class.df <- data.frame(list(apply(train_tweets_new.df, 1, function(x) get_sentiment(tolower(gsub(\"[()]\", \"\", x))) )))\n\ncolnames(train_tweets_new.df)[1]<- c(\"text\")\n\n#remove all mention of \"love\" from the text\ntrain_tweets_rmvd.df <- data.frame(sapply(train_tweets_new.df$text, function(x) gsub(\"love\", \"\", tolower(x))))\n#remove all mention of \"hate from the text\"\ntrain_tweets_rmvd.df <- data.frame(sapply(train_tweets_rmvd.df, function(x) gsub(\"hate\", \"\", tolower(x))))\n\n#data preprocessing\ncreate_and_process_corp <- function(data_frame) {\n  \n  cs <- Corpus(VectorSource(data_frame))\n  cs<-tm_map(cs, removePunctuation, lazy=FALSE)\n  cs<-tm_map(cs, stripWhitespace, lazy=FALSE)\n  cs<-tm_map(cs, content_transformer(tolower), lazy=FALSE)\n  cs<-tm_map(cs, removeWords, stopwords(\"english\"), lazy=FALSE)\n  cs<-tm_map(cs, stemDocument, lazy=FALSE)\n  \n  return(cs)\n}\ncorpus <- create_and_process_corp(train_tweets_rmvd.df[,1]);\n\n\ntdm <- TermDocumentMatrix(corpus)\nm <- as.matrix(tdm)\nv <- sort(rowSums(m), decreasing=TRUE)\nN <- 30\nhead(v, N)\nfeatures <- names(head(v,N))\n\ntdm_remsparse <- TermDocumentMatrix(corpus, control = list(dictionary = features ))\ntdm_remsp_df <- as.data.frame(as.matrix(tdm_remsparse))\ntdm_remsp_df <- t(tdm_remsp_df)\ntdm_remsp_df <- as.data.frame(tdm_remsp_df)\ntdm_remsp_df[\"label\"]= train_org_class.df\ntrainingdatastream <- datastream_dataframe(data=tdm_remsp_df)\n\nctrl <- MOAoptions(model = \"NaiveBayes\")\nmymodel <- NaiveBayes(control=ctrl)\n#mymodel\n\nmyModel <- trainMOA(model = mymodel, formula=label~., data = trainingdatastream, reset = FALSE, trace = FALSE)\n\n#Fetching, train and predict the test data set\npredict_test_data <- function(trained_model, feature_list) {\n  \n  test_tweets.df=get_love_hate_tweets(4);\n  cat(\"test_tweets.df: \" ,nrow(test_tweets.df), \"\\n\")\n  test_tweets_new.df <- get_tweet_text(test_tweets.df);\n  \n  test_sentiment.df <- data.frame(list(apply(test_tweets_new.df, 1, function(x) get_sentiment(tolower(gsub(\"[()]\", \"\", x))) )))\n  cat(\"org sentiment: \" ,nrow(test_sentiment.df), \"\\n\")\n  \n  colnames(test_tweets_new.df)[1]<- c(\"text\")\n  \n  test_tweets_rmvd.df <- data.frame(sapply(test_tweets_new.df$text, function(x) gsub(\"love\", \"\", tolower(x))))\n  test_tweets_rmvd.df <- data.frame(sapply(test_tweets_rmvd.df, function(x) gsub(\"hate\", \"\", tolower(x))))\n  \n  corpus_test <- create_and_process_corp(test_tweets_rmvd.df[,1]);\n  \n  dtm_test <- DocumentTermMatrix(corpus_test, control = list(dictionary = feature_list))\n  \n  dtm_test_df <- as.data.frame(as.matrix(dtm_test))\n  i=1;\n  nrow(dtm_test_df)\n  cat(\"nrow: \", nrow(dtm_test_df), \"\\n\")\n  scores = c()\n  testDataStream = datastream_dataframe(data = dtm_test_df)\n  \n  while(testDataStream$processed < nrow(dtm_test_df) ){\n    value <- predict(trained_model, newdata=testDataStream$get_points(1), type=\"response\")\n    scores <- append(scores, value)\n    trained_model <- get_updated_model(trained_model$model, dtm_test_df[i,], test_sentiment.df[i,1], i)\n    cat(i, \"\\n\")\n    i <- i+1\n  }\n  result_table=table(scores, test_sentiment.df[,1])\n  \n  accuracy=(result_table[1,1]+result_table[2,2])/(result_table[1,1]+result_table[1,2]+result_table[2,1]+result_table[2,2])\n  \n  function_output=list(model=trained_model,accuracy=accuracy)\n  \n  return(function_output)\n  #return(c(trained_model, scores, test_sentiment.df[,1]))\n}\n\nprediction_results <- predict_test_data(myModel, features)\nmyModel <- prediction_results$model\nmodel_accuracy <-prediction_results$accuracy\nmodel_accuracy\n",
    "created" : 1428707033122.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3090085358",
    "id" : "4D1D704B",
    "lastKnownWriteTime" : 1428710426,
    "path" : "~/twitterR/R/twitterR.R",
    "project_path" : "R/twitterR.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}